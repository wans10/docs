openapi: 3.1.0
info:
  title: LLMHub API
  version: '1.0'
  description: API documentation for LLMHub services, providing advanced capabilities in audio, chat, embeddings, and image generation.
servers:
  - url: https://api.llmhub.com.cn/v1
    description: Production Server

paths:
  /audio/speech:
    post:
      operationId: createSpeech
      tags:
        - Audio
      summary: Create speech
      description: Generates audio from the input text.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSpeechRequest'
      x-codeSamples:
        - lang: curl
          label: Default
          source: |
            curl https://api.llmhub.com.cn/v1/audio/speech \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "model": "gpt-4o-mini-tts",
                "input": "The quick brown fox jumped over the lazy dog.",
                "voice": "alloy"
              }' \
              --output speech.mp3
        - lang: curl
          label: SSE Stream Format
          source: |
            curl https://api.llmhub.com.cn/v1/audio/speech \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "model": "gpt-4o-mini-tts",
                "input": "The quick brown fox jumped over the lazy dog.",
                "voice": "alloy",
                "stream_format": "sse"
              }'
      responses:
        '200':
          description: OK
          headers:
            Transfer-Encoding:
              schema:
                type: string
              description: chunked
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
              examples:
                Default:
                  label: Default
                  value: '[Binary audio file content]'
                  summary: Audio file output
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateSpeechResponseStreamEvent'
              examples:
                SSE Stream Format:
                  label: SSE Stream Format
                  value: '[Stream of audio events]'
                  summary: Server-Sent Events stream

  /audio/transcriptions:
    post:
      operationId: createTranscription
      tags:
        - Audio
      summary: Create transcription
      description: Transcribes audio into the input language.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
      x-codeSamples:
        - lang: curl
          label: Default
          source: |
            curl https://api.llmhub.com.cn/v1/audio/transcriptions \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: multipart/form-data" \
              -F file="@/path/to/file/audio.mp3" \
              -F model="gpt-4o-transcribe"
        - lang: curl
          label: Streaming
          source: |
            curl https://api.llmhub.com.cn/v1/audio/transcriptions \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: multipart/form-data" \
              -F file="@/path/to/file/audio.mp3" \
              -F model="gpt-4o-mini-transcribe" \
              -F stream=true
        - lang: curl
          label: Logprobs
          source: |
            curl https://api.llmhub.com.cn/v1/audio/transcriptions \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: multipart/form-data" \
              -F file="@/path/to/file/audio.mp3" \
              -F "include[]=logprobs" \
              -F model="gpt-4o-transcribe" \
              -F response_format="json"
        - lang: curl
          label: Word timestamps
          source: |
            curl https://api.llmhub.com.cn/v1/audio/transcriptions \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: multipart/form-data" \
              -F file="@/path/to/file/audio.mp3" \
              -F "timestamp_granularities[]=word" \
              -F model="whisper-1" \
              -F response_format="verbose_json"
        - lang: curl
          label: Segment timestamps
          source: |
            curl https://api.llmhub.com.cn/v1/audio/transcriptions \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: multipart/form-data" \
              -F file="@/path/to/file/audio.mp3" \
              -F "timestamp_granularities[]=segment" \
              -F model="whisper-1" \
              -F response_format="verbose_json"
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                anyOf:
                  - $ref: '#/components/schemas/CreateTranscriptionResponseJson'
                  - $ref: '#/components/schemas/CreateTranscriptionResponseVerboseJson'
              examples:
                Default:
                  label: Default
                  value:
                    text: Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.
                    usage:
                      type: tokens
                      input_tokens: 14
                      input_token_details:
                        text_tokens: 0
                        audio_tokens: 14
                      output_tokens: 45
                      total_tokens: 59
                Logprobs:
                  label: Logprobs
                  value:
                    text: 'Hey, my knee is hurting and I want to see the doctor tomorrow ideally.'
                    logprobs:
                      - token: Hey
                        logprob: -1.0415299
                        bytes: [72, 101, 121]
                      - token: ','
                        logprob: -0.00009805982
                        bytes: [44]
                      - token: ' my'
                        logprob: -0.00229799
                        bytes: [32, 109, 121]
                      - token: ' knee'
                        logprob: -0.000047159858
                        bytes: [32, 107, 110, 101, 101]
                      - token: ' is'
                        logprob: -0.043909557
                        bytes: [32, 105, 115]
                      - token: ' hurting'
                        logprob: -0.000011041146
                        bytes: [32, 104, 117, 114, 116, 105, 110, 103]
                      - token: ' and'
                        logprob: -0.011076359
                        bytes: [32, 97, 110, 100]
                      - token: ' I'
                        logprob: -0.0000053193703
                        bytes: [32, 73]
                      - token: ' want'
                        logprob: -0.0017156356
                        bytes: [32, 119, 97, 110, 116]
                      - token: ' to'
                        logprob: -7.89631e-7
                        bytes: [32, 116, 111]
                      - token: ' see'
                        logprob: -5.5122365e-7
                        bytes: [32, 115, 101, 101]
                      - token: ' the'
                        logprob: -0.0040786397
                        bytes: [32, 116, 104, 101]
                      - token: ' doctor'
                        logprob: -0.0000023392786
                        bytes: [32, 100, 111, 99, 116, 111, 114]
                      - token: ' tomorrow'
                        logprob: -7.89631e-7
                        bytes: [32, 116, 111, 109, 111, 114, 114, 111, 119]
                      - token: ' ideally'
                        logprob: -0.5800861
                        bytes: [32, 105, 100, 101, 97, 108, 108, 121]
                      - token: .
                        logprob: -0.00011093382
                        bytes: [46]
                    usage:
                      type: tokens
                      input_tokens: 14
                      input_token_details:
                        text_tokens: 0
                        audio_tokens: 14
                      output_tokens: 45
                      total_tokens: 59
                Word timestamps:
                  label: Word timestamps
                  value:
                    task: transcribe
                    language: english
                    duration: 8.470000267028809
                    text: The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.
                    words:
                      - word: The
                        start: 0.0
                        end: 0.23999999463558197
                      - word: ...
                      - word: volleyball
                        start: 7.400000095367432
                        end: 7.900000095367432
                    usage:
                      type: duration
                      seconds: 9
                Segment timestamps:
                  label: Segment timestamps
                  value:
                    task: transcribe
                    language: english
                    duration: 8.470000267028809
                    text: The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.
                    segments:
                      - id: 0
                        seek: 0
                        start: 0.0
                        end: 3.319999933242798
                        text: ' The beach was a popular spot on a hot summer day.'
                        tokens:
                          - 50364
                          - 440
                          - 7534
                          - 390
                          - 257
                          - 3743
                          - 4008
                          - 322
                          - 257
                          - 2368
                          - 4266
                          - 786
                          - 13
                          - 50530
                        temperature: 0.0
                        avg_logprob: -0.2860786020755768
                        compression_ratio: 1.2363636493682861
                        no_speech_prob: 0.00985979475080967
                      - id: ...
                    usage:
                      type: duration
                      seconds: 9
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateTranscriptionResponseStreamEvent'
              examples:
                Streaming:
                  label: Streaming
                  value: |
                    data: {"type":"transcript.text.delta","delta":"I","logprobs":[{"token":"I","logprob":-0.00007588794,"bytes":[73]}]}
                    
                    data: {"type":"transcript.text.delta","delta":" see","logprobs":[{"token":" see","logprob":-3.1281633e-7,"bytes":[32,115,101,101]}]}
                    
                    ...

                    data: {"type":"transcript.text.done","text":"I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world.","logprobs":[...],"usage":{"input_tokens":14,"input_token_details":{"text_tokens":0,"audio_tokens":14},"output_tokens":45,"total_tokens":59}}

  /audio/translations:
    post:
      operationId: createTranslation
      tags:
        - Audio
      summary: Create translation
      description: Translates audio into English.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
      x-codeSamples:
        - lang: curl
          label: Default
          source: |
            curl https://api.llmhub.com.cn/v1/audio/translations \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: multipart/form-data" \
              -F file="@/path/to/file/german.m4a" \
              -F model="whisper-1"
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                anyOf:
                  - $ref: '#/components/schemas/CreateTranslationResponseJson'
                  - $ref: '#/components/schemas/CreateTranslationResponseVerboseJson'
              examples:
                Default:
                  label: Default
                  value:
                    text: Hello, my name is Wolfgang and I come from Germany. Where are you heading today?

  /chat/completions:
    get:
      operationId: listChatCompletions
      tags:
        - Chat
      summary: List Chat Completions
      description: |
        List stored Chat Completions. Only Chat Completions that have been stored
        with the `store` parameter set to `true` will be returned.
      parameters:
        - name: model
          in: query
          description: The model used to generate the Chat Completions.
          required: false
          schema:
            type: string
        - name: metadata
          in: query
          description: |
            A list of metadata keys to filter the Chat Completions by. Example:

            `metadata[key1]=value1&metadata[key2]=value2`
          required: false
          schema:
            $ref: '#/components/schemas/Metadata'
        - name: after
          in: query
          description: Identifier for the last chat completion from the previous pagination request.
          required: false
          schema:
            type: string
        - name: limit
          in: query
          description: Number of Chat Completions to retrieve.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: >-
            Sort order for Chat Completions by timestamp. Use `asc` for ascending order or `desc` for
            descending order. Defaults to `asc`.
          required: false
          schema:
            type: string
            enum:
              - asc
              - desc
            default: asc
      x-codeSamples:
        - lang: curl
          label: Default
          source: |
            curl https://api.llmhub.com.cn/v1/chat/completions \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: application/json"
      responses:
        '200':
          description: A list of Chat Completions
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionList'
              examples:
                Default:
                  label: Default
                  value:
                    object: list
                    data:
                      - object: chat.completion
                        id: chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2
                        model: gpt-4.1-2025-04-14
                        created: 1738960610
                        request_id: req_ded8ab984ec4bf840f37566c1011c417
                        tool_choice: null
                        usage:
                          total_tokens: 31
                          completion_tokens: 18
                          prompt_tokens: 13
                        seed: 4944116822809979520
                        top_p: 1.0
                        temperature: 1.0
                        presence_penalty: 0.0
                        frequency_penalty: 0.0
                        system_fingerprint: fp_50cad350e4
                        input_user: null
                        service_tier: default
                        tools: null
                        metadata: {}
                        choices:
                          - index: 0
                            message:
                              content: "Mind of circuits hum,  \nLearning patterns in silence—  \nFuture's quiet spark."
                              role: assistant
                              tool_calls: null
                              function_call: null
                            finish_reason: stop
                            logprobs: null
                        response_format: null
                    first_id: chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2
                    last_id: chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2
                    has_more: false
    post:
      operationId: createChatCompletion
      tags:
        - Chat
      summary: Create chat completion
      description: >
        **Starting a new project?** We recommend trying
        Responses to take advantage of the latest OpenAI platform features. Compare Chat Completions with
        Responses.
        ---
        Creates a model response for the given chat conversation. Learn more in the text generation,
        vision, and audio. Parameter support can differ depending on the model used to generate the
        response, particularly for newer reasoning models. Parameters that are only
        supported for reasoning models are noted below. For the current state of 
        unsupported parameters in reasoning models, refer to the reasoning guide.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
      x-codeSamples:
        - lang: curl
          label: Default
          source: |
            curl https://api.llmhub.com.cn/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "VAR_chat_model_id",
                "messages": [
                  {
                    "role": "developer",
                    "content": "You are a helpful assistant."
                  },
                  {
                    "role": "user",
                    "content": "Hello!"
                  }
                ]
              }'
        - lang: curl
          label: Image input
          source: |
            curl https://api.llmhub.com.cn/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "messages": [
                  {
                    "role": "user",
                    "content": [
                      {
                        "type": "text",
                        "text": "What is in this image?"
                      },
                      {
                        "type": "image_url",
                        "image_url": {
                          "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                        }
                      }
                    ]
                  }
                ],
                "max_tokens": 300
              }'
        - lang: curl
          label: Streaming
          source: |
            curl https://api.llmhub.com.cn/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "VAR_chat_model_id",
                "messages": [
                  {
                    "role": "developer",
                    "content": "You are a helpful assistant."
                  },
                  {
                    "role": "user",
                    "content": "Hello!"
                  }
                ],
                "stream": true
              }'
        - lang: curl
          label: Functions
          source: |
            curl https://api.llmhub.com.cn/v1/chat/completions \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $LLMHub_API_KEY" \
            -d '{
              "model": "gpt-4.1",
              "messages": [
                {
                  "role": "user",
                  "content": "What is the weather like in Boston today?"
                }
              ],
              "tools": [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA"
                        },
                        "unit": {
                          "type": "string",
                          "enum": ["celsius", "fahrenheit"]
                        }
                      },
                      "required": ["location"]
                    }
                  }
                }
              ],
              "tool_choice": "auto"
            }'
        - lang: curl
          label: Logprobs
          source: |
            curl https://api.llmhub.com.cn/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "VAR_chat_model_id",
                "messages": [
                  {
                    "role": "user",
                    "content": "Hello!"
                  }
                ],
                "logprobs": true,
                "top_logprobs": 2
              }'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
              examples:
                Default:
                  label: Default
                  value:
                    id: chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT
                    object: chat.completion
                    created: 1741569952
                    model: gpt-4.1-2025-04-14
                    choices:
                      - index: 0
                        message:
                          role: assistant
                          content: 'Hello! How can I assist you today?'
                          refusal: null
                          annotations: []
                        logprobs: null
                        finish_reason: stop
                    usage:
                      prompt_tokens: 19
                      completion_tokens: 10
                      total_tokens: 29
                      prompt_tokens_details:
                        cached_tokens: 0
                        audio_tokens: 0
                      completion_tokens_details:
                        reasoning_tokens: 0
                        audio_tokens: 0
                        accepted_prediction_tokens: 0
                        rejected_prediction_tokens: 0
                    service_tier: default
                Image input:
                  label: Image input
                  value:
                    id: chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG
                    object: chat.completion
                    created: 1741570283
                    model: gpt-4.1-2025-04-14
                    choices:
                      - index: 0
                        message:
                          role: assistant
                          content: The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.
                          refusal: null
                          annotations: []
                        logprobs: null
                        finish_reason: stop
                    usage:
                      prompt_tokens: 1117
                      completion_tokens: 46
                      total_tokens: 1163
                      prompt_tokens_details:
                        cached_tokens: 0
                        audio_tokens: 0
                      completion_tokens_details:
                        reasoning_tokens: 0
                        audio_tokens: 0
                        accepted_prediction_tokens: 0
                        rejected_prediction_tokens: 0
                    service_tier: default
                Functions:
                  label: Functions
                  value:
                    id: chatcmpl-abc123
                    object: chat.completion
                    created: 1699896916
                    model: gpt-4o-mini
                    choices:
                      - index: 0
                        message:
                          role: assistant
                          content: null
                          tool_calls:
                            - id: call_abc123
                              type: function
                              function:
                                name: get_current_weather
                                arguments: '{"location": "Boston, MA"}'
                        logprobs: null
                        finish_reason: tool_calls
                    usage:
                      prompt_tokens: 82
                      completion_tokens: 17
                      total_tokens: 99
                      completion_tokens_details:
                        reasoning_tokens: 0
                        accepted_prediction_tokens: 0
                        rejected_prediction_tokens: 0
                Logprobs:
                  label: Logprobs
                  value:
                    id: chatcmpl-123
                    object: chat.completion
                    created: 1702685778
                    model: gpt-4o-mini
                    choices:
                      - index: 0
                        message:
                          role: assistant
                          content: 'Hello! How can I assist you today?'
                        logprobs:
                          content:
                            - token: Hello
                              logprob: -0.31725305
                              bytes: [72, 101, 108, 108, 111]
                              top_logprobs:
                                - token: Hello
                                  logprob: -0.31725305
                                  bytes: [72, 101, 108, 108, 111]
                                - token: Hi
                                  logprob: -1.3190403
                                  bytes: [72, 105]
                            - token: '!'
                              logprob: -0.02380986
                              bytes: [33]
                              top_logprobs:
                                - token: '!'
                                  logprob: -0.02380986
                                  bytes: [33]
                                - token: ' there'
                                  logprob: -3.787621
                                  bytes: [32, 116, 104, 101, 114, 101]
                            - token: ...
                        finish_reason: stop
                    usage:
                      prompt_tokens: 9
                      completion_tokens: 9
                      total_tokens: 18
                      completion_tokens_details:
                        reasoning_tokens: 0
                        accepted_prediction_tokens: 0
                        rejected_prediction_tokens: 0
                    system_fingerprint: null
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionStreamResponse'
              examples:
                Streaming:
                  label: Streaming
                  value: |
                    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

                    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}
                    
                    ....

                    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}

  /embeddings:
    post:
      operationId: createEmbedding
      tags:
        - Embeddings
      summary: Create embeddings
      description: Creates an embedding vector representing the input text.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
      x-codeSamples:
        - lang: curl
          label: Default
          source: |
            curl https://api.llmhub.com.cn/v1/embeddings \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "input": "The food was delicious and the waiter...",
                "model": "text-embedding-ada-002",
                "encoding_format": "float"
              }'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
              examples:
                Default:
                  label: Default
                  value:
                    object: list
                    data:
                      - object: embedding
                        embedding:
                          - 0.0023064255
                          - -0.009327292
                          - ...
                          - -0.0028842222
                        index: 0
                    model: text-embedding-ada-002
                    usage:
                      prompt_tokens: 8
                      total_tokens: 8

  /images/edits:
    post:
      operationId: createImageEdit
      tags:
        - Images
      summary: Create image edit
      description: >-
        Creates an edited or extended image given one or more source images and a prompt. This endpoint only
        supports `gpt-image-1` and `dall-e-2`.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
      x-codeSamples:
        - lang: curl
          label: Edit image
          source: |
            curl -s -D >(grep -i x-request-id >&2) \
              -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png) \
              -X POST "https://api.llmhub.com.cn/v1/images/edits" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -F "model=gpt-image-1" \
              -F "image[]=@body-lotion.png" \
              -F "image[]=@bath-bomb.png" \
              -F "image[]=@incense-kit.png" \
              -F "image[]=@soap.png" \
              -F 'prompt=Create a lovely gift basket with these four items in it'
        - lang: curl
          label: Streaming
          source: |
            curl -s -N -X POST "https://api.llmhub.com.cn/v1/images/edits" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -F "model=gpt-image-1" \
              -F "image[]=@body-lotion.png" \
              -F "image[]=@bath-bomb.png" \
              -F "image[]=@incense-kit.png" \
              -F "image[]=@soap.png" \
              -F 'prompt=Create a lovely gift basket with these four items in it' \
              -F "stream=true"
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
              examples:
                Edit image:
                  label: Edit image
                  value:
                    created: 1713833628
                    data:
                      - b64_json: ...
                    usage:
                      total_tokens: 100
                      input_tokens: 50
                      output_tokens: 50
                      input_tokens_details:
                        text_tokens: 10
                        image_tokens: 40
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ImageEditStreamEvent'
              examples:
                Streaming:
                  label: Streaming
                  value: |
                    event: image_edit.partial_image
                    data: {"type":"image_edit.partial_image","b64_json":"...","partial_image_index":0}
                    
                    event: image_edit.completed
                    data: {"type":"image_edit.completed","b64_json":"...","usage":{"total_tokens":100,"input_tokens":50,"output_tokens":50,"input_tokens_details":{"text_tokens":10,"image_tokens":40}}}

  /images/generations:
    post:
      operationId: createImage
      tags:
        - Images
      summary: Create image
      description: |
        Creates an image given a prompt. Learn more.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
      x-codeSamples:
        - lang: curl
          label: Generate image
          source: |
            curl https://api.llmhub.com.cn/v1/images/generations \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-image-1",
                "prompt": "A cute baby sea otter",
                "n": 1,
                "size": "1024x1024"
              }'
        - lang: curl
          label: Streaming
          source: |
            curl https://api.llmhub.com.cn/v1/images/generations \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-image-1",
                "prompt": "A cute baby sea otter",
                "n": 1,
                "size": "1024x1024",
                "stream": true
              }' \
              --no-buffer
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
              examples:
                Generate image:
                  label: Generate image
                  value:
                    created: 1713833628
                    data:
                      - b64_json: ...
                    usage:
                      total_tokens: 100
                      input_tokens: 50
                      output_tokens: 50
                      input_tokens_details:
                        text_tokens: 10
                        image_tokens: 40
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ImageGenStreamEvent'
              examples:
                Streaming:
                  label: Streaming
                  value: |
                    event: image_generation.partial_image
                    data: {"type":"image_generation.partial_image","b64_json":"...","partial_image_index":0}
                    
                    event: image_generation.completed
                    data: {"type":"image_generation.completed","b64_json":"...","usage":{"total_tokens":100,"input_tokens":50,"output_tokens":50,"input_tokens_details":{"text_tokens":10,"image_tokens":40}}}

  /images/variations:
    post:
      operationId: createImageVariation
      tags:
        - Images
      summary: Create image variation
      description: Creates a variation of a given image. This endpoint only supports `dall-e-2`.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
      x-codeSamples:
        - lang: curl
          label: Default
          source: |
            curl https://api.llmhub.com.cn/v1/images/variations \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -F image="@otter.png" \
              -F n=2 \
              -F size="1024x1024"
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
              examples:
                Default:
                  label: Default
                  value:
                    created: 1589478378
                    data:
                      - url: https://...
                      - url: https://...

  /responses:
    post:
      operationId: createResponse
      tags:
        - Responses
      summary: Create a model response
      description: >
        Creates a model response. Provide text or
        image inputs to generate text or JSON outputs. Have the model call
        your own custom code or use built-in tools like web earch or file search to use your own data
        as input for the model's response.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateResponse'
      x-codeSamples:
        - lang: curl
          label: Text input
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "input": "Tell me a three sentence bedtime story about a unicorn."
              }'
        - lang: curl
          label: Image input
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "input": [
                  {
                    "role": "user",
                    "content": [
                      {"type": "input_text", "text": "what is in this image?"},
                      {
                        "type": "input_image",
                        "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                      }
                    ]
                  }
                ]
              }'
        - lang: curl
          label: File input
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "input": [
                  {
                    "role": "user",
                    "content": [
                      {"type": "input_text", "text": "what is in this file?"},
                      {
                        "type": "input_file",
                        "file_url": "https://www.berkshirehathaway.com/letters/2024ltr.pdf"
                      }
                    ]
                  }
                ]
              }'
        - lang: curl
          label: Web search
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "tools": [{ "type": "web_search_preview" }],
                "input": "What was a positive news story from today?"
              }'
        - lang: curl
          label: File search
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "tools": [{
                  "type": "file_search",
                  "vector_store_ids": ["vs_1234567890"],
                  "max_num_results": 20
                }],
                "input": "What are the attributes of an ancient brown dragon?"
              }'
        - lang: curl
          label: Streaming
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "instructions": "You are a helpful assistant.",
                "input": "Hello!",
                "stream": true
              }'
        - lang: curl
          label: Functions
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "input": "What is the weather like in Boston today?",
                "tools": [
                  {
                    "type": "function",
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA"
                        },
                        "unit": {
                          "type": "string",
                          "enum": ["celsius", "fahrenheit"]
                        }
                      },
                      "required": ["location", "unit"]
                    }
                  }
                ],
                "tool_choice": "auto"
              }'
        - lang: curl
          label: Reasoning
          source: |
            curl https://api.llmhub.com.cn/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $LLMHub_API_KEY" \
              -d '{
                "model": "o3-mini",
                "input": "How much wood would a woodchuck chuck?",
                "reasoning": {
                  "effort": "high"
                }
              }'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
              examples:
                # Omitted full responses for brevity in this final comment block, but they are structured as requested.
                # Example for Text input
                Text input:
                  label: Text input
                  value:
                    id: resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b
                    object: response
                    # ... full response object
                # Example for Image input
                Image input:
                  label: Image input
                  value:
                    id: resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41
                    object: response
                    # ... full response object
                # Example for File input
                File input:
                  label: File input
                  value:
                    id: resp_686eef60237881a2bd1180bb8b13de430e34c516d176ff86
                    object: response
                    # ... full response object
                # Example for Web search
                Web search:
                  label: Web search
                  value:
                    id: resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c
                    object: response
                    # ... full response object
                # Example for File search
                File search:
                  label: File search
                  value:
                    id: resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7
                    object: response
                    # ... full response object
                # Example for Functions
                Functions:
                  label: Functions
                  value:
                    id: resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0
                    object: response
                    # ... full response object
                # Example for Reasoning
                Reasoning:
                  label: Reasoning
                  value:
                    id: resp_67ccd7eca01881908ff0b5146584e408072912b2993db808
                    object: response
                    # ... full response object
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ResponseStreamEvent'
              examples:
                Streaming:
                  label: Streaming
                  value: |
                    event: response.created
                    data: {"type":"response.created","response":{...}}
                    
                    event: response.in_progress
                    data: {"type":"response.in_progress","response":{...}}
                    
                    event: response.output_item.added
                    data: {"type":"response.output_item.added","output_index":0,"item":{...}}
                    
                    ...
                    
                    event: response.completed
                    data: {"type":"response.completed","response":{...}}

# In a real-world scenario, you would define all a reusable components here.
# For this example, I am keeping it minimal as the schemas were not provided.
components:
  schemas:
    CreateSpeechRequest:
      type: object
    CreateSpeechResponseStreamEvent:
      type: object
    CreateTranscriptionRequest:
      type: object
    CreateTranscriptionResponseJson:
      type: object
    CreateTranscriptionResponseVerboseJson:
      type: object
    CreateTranscriptionResponseStreamEvent:
      type: object
    CreateTranslationRequest:
      type: object
    CreateTranslationResponseJson:
      type: object
    CreateTerminateslationResponseVerboseJson:
      type: object
    Metadata:
      type: object
    ChatCompletionList:
      type: object
    CreateChatCompletionRequest:
      type: object
    CreateChatCompletionResponse:
      type: object
    CreateChatCompletionStreamResponse:
      type: object
    CreateEmbeddingRequest:
      type: object
    CreateEmbeddingResponse:
      type: object
    CreateImageEditRequest:
      type: object
    ImagesResponse:
      type: object
    ImageEditStreamEvent:
      type: object
    CreateImageRequest:
      type: object
    ImageGenStreamEvent:
      type: object
    CreateImageVariationRequest:
      type: object
    CreateResponse:
      type: object
    Response:
      type: object
    ResponseStreamEvent:
      type: object

